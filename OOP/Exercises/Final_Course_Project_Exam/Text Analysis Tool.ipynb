{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Course Project / Exam\n",
    "\n",
    "#### Remmy Bisimbeko - B26099 - J24M19/011\n",
    "#### My GitHub - https://github.com/RemmyBisimbeko/Data-Science\n",
    "\n",
    "#### 5. Text Analysis Tool\n",
    "* Text Analysis Tool using a text analysis API: Create a text analysis tool that leverages a text analysis API to perform sentiment analysis, keyword extraction, entity recognition, language detection, and other text processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a real text analysis API called MonkeyLearn API, which offers a range of text analysis functionalities such as sentiment analysis, keyword extraction, and entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "    \"\"\"\n",
    "    Analyze the given text using TextBlob.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: The text to analyze\n",
    "    \n",
    "    Returns:\n",
    "    - Analysis results as a TextBlob object\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    return blob\n",
    "\n",
    "def display_analysis_results(blob):\n",
    "    \"\"\"\n",
    "    Display the analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    - blob: TextBlob object containing the analysis results\n",
    "    \"\"\"\n",
    "    print(\"Sentiment:\", blob.sentiment)\n",
    "    print(\"Parts of Speech:\", blob.tags)\n",
    "    print(\"Noun Phrases:\", blob.noun_phrases)\n",
    "    print(\"Word Counts:\", len(blob.words))\n",
    "    print(\"Sentence Counts:\", len(blob.sentences))\n",
    "    print(\"Sentences:\")\n",
    "    for sentence in blob.sentences:\n",
    "        print(\"-\", sentence)\n",
    "    print(\"Tokenization:\")\n",
    "    for word in blob.words:\n",
    "        print(\"-\", word)\n",
    "    print(\"Sentiment Polarity for each Sentence:\")\n",
    "    for sentence in blob.sentences:\n",
    "        print(\"-\", sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Sentiment(polarity=0.14814814814814817, subjectivity=0.5338624338624338)\n",
      "Parts of Speech: [('TextBlob', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('simple', 'JJ'), ('Python', 'NNP'), ('library', 'NN'), ('for', 'IN'), ('processing', 'VBG'), ('textual', 'JJ'), ('data', 'NNS'), ('It', 'PRP'), ('provides', 'VBZ'), ('a', 'DT'), ('simple', 'JJ'), ('API', 'NNP'), ('for', 'IN'), ('diving', 'VBG'), ('into', 'IN'), ('common', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('NLP', 'NNP'), ('tasks', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('part-of-speech', 'JJ'), ('tagging', 'NN'), ('noun', 'JJ'), ('phrase', 'NN'), ('extraction', 'NN'), ('sentiment', 'NN'), ('analysis', 'NN'), ('classification', 'NN'), ('translation', 'NN'), ('and', 'CC'), ('more', 'JJR'), ('TextBlob', 'NNP'), ('stands', 'VBZ'), ('on', 'IN'), ('the', 'DT'), ('shoulders', 'NNS'), ('of', 'IN'), ('NLTK', 'NNP'), ('and', 'CC'), ('pattern', 'NN'), ('and', 'CC'), ('plays', 'NNS'), ('nicely', 'RB'), ('with', 'IN'), ('both', 'DT'), ('It', 'PRP'), ('is', 'VBZ'), ('inspired', 'VBN'), ('by', 'IN'), ('and', 'CC'), ('borrows', 'NNS'), ('from', 'IN'), ('projects', 'NNS'), ('like', 'IN'), ('Pattern', 'NNP'), ('and', 'CC'), ('NLTK', 'NNP'), ('TextBlob', 'NNP'), ('is', 'VBZ'), ('easy', 'JJ'), ('to', 'TO'), ('install', 'VB'), ('and', 'CC'), ('use', 'VB'), ('and', 'CC'), ('has', 'VBZ'), ('a', 'DT'), ('simple', 'JJ'), ('API', 'NNP'), ('TextBlob', 'NNP'), ('is', 'VBZ'), ('compatible', 'JJ'), ('with', 'IN'), ('Python', 'NNP'), ('2.7', 'CD'), ('and', 'CC'), ('3.3+', 'CD')]\n",
      "Noun Phrases: ['textblob', 'python', 'processing textual data', 'api', 'common natural language processing', 'nlp', 'noun phrase extraction', 'sentiment analysis', 'textblob', 'nltk', 'pattern', 'nltk', 'textblob', 'api', 'textblob', 'python']\n",
      "Word Counts: 83\n",
      "Sentence Counts: 6\n",
      "Sentences:\n",
      "- TextBlob is a simple Python library for processing textual data.\n",
      "- It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
      "- TextBlob stands on the shoulders of NLTK and pattern and plays nicely with both.\n",
      "- It is inspired by and borrows from projects like Pattern and NLTK.\n",
      "- TextBlob is easy to install and use and has a simple API.\n",
      "- TextBlob is compatible with Python 2.7 and 3.3+.\n",
      "Tokenization:\n",
      "- TextBlob\n",
      "- is\n",
      "- a\n",
      "- simple\n",
      "- Python\n",
      "- library\n",
      "- for\n",
      "- processing\n",
      "- textual\n",
      "- data\n",
      "- It\n",
      "- provides\n",
      "- a\n",
      "- simple\n",
      "- API\n",
      "- for\n",
      "- diving\n",
      "- into\n",
      "- common\n",
      "- natural\n",
      "- language\n",
      "- processing\n",
      "- NLP\n",
      "- tasks\n",
      "- such\n",
      "- as\n",
      "- part-of-speech\n",
      "- tagging\n",
      "- noun\n",
      "- phrase\n",
      "- extraction\n",
      "- sentiment\n",
      "- analysis\n",
      "- classification\n",
      "- translation\n",
      "- and\n",
      "- more\n",
      "- TextBlob\n",
      "- stands\n",
      "- on\n",
      "- the\n",
      "- shoulders\n",
      "- of\n",
      "- NLTK\n",
      "- and\n",
      "- pattern\n",
      "- and\n",
      "- plays\n",
      "- nicely\n",
      "- with\n",
      "- both\n",
      "- It\n",
      "- is\n",
      "- inspired\n",
      "- by\n",
      "- and\n",
      "- borrows\n",
      "- from\n",
      "- projects\n",
      "- like\n",
      "- Pattern\n",
      "- and\n",
      "- NLTK\n",
      "- TextBlob\n",
      "- is\n",
      "- easy\n",
      "- to\n",
      "- install\n",
      "- and\n",
      "- use\n",
      "- and\n",
      "- has\n",
      "- a\n",
      "- simple\n",
      "- API\n",
      "- TextBlob\n",
      "- is\n",
      "- compatible\n",
      "- with\n",
      "- Python\n",
      "- 2.7\n",
      "- and\n",
      "- 3.3\n",
      "Sentiment Polarity for each Sentence:\n",
      "- 0.0\n",
      "- 0.06000000000000001\n",
      "- 0.6\n",
      "- 0.0\n",
      "- 0.21666666666666667\n",
      "- 0.0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Analyze text\n",
    "    text = \"TextBlob is a simple Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. TextBlob stands on the shoulders of NLTK and pattern and plays nicely with both. It is inspired by and borrows from projects like Pattern and NLTK. TextBlob is easy to install and use and has a simple API. TextBlob is compatible with Python 2.7 and 3.3+.\"\n",
    "    analysis_results = analyze_text(text)\n",
    "    \n",
    "    # Display the analysis results\n",
    "    display_analysis_results(analysis_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
